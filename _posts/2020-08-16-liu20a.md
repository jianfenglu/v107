---
title: 'SelectNet: Learning to Sample from the Wild for Imbalanced Data Training'
abstract: "  Supervised learning from training data with imbalanced class sizes, a
  commonly encountered scenario in real applications such as anomaly/fraud detection,
  has long been considered a significant challenge in machine learning. Motivated
  by recent progress in curriculum and self-paced  learning, we propose to adopt a
  semi-supervised learning paradigm by training a deep neural network, referred to
  as SelectNet, to selectively add unlabelled data together with their predicted labels
  to the training dataset. Unlike existing techniques designed to tackle the difficulty
  in dealing with class imbalanced training data such as resampling, cost-sensitive
  learning, and margin-based learning, SelectNet provides an end-to-end approach for
  learning from important unlabelled data “in the wild” that most likely belong to
  the under-sampled classes in the training data, thus gradually mitigates the imbalance
  in the data used for training the classifier. We demonstrate the efficacy of SelectNet
  through extensive numerical experiments on standard datasets in computer vision. "
layout: inproceedings
series: Proceedings of Machine Learning Research
id: liu20a
month: 0
tex_title: "{SelectNet: L}earning to Sample from the Wild for Imbalanced Data Training"
firstpage: 193
lastpage: 206
page: 193-206
order: 193
cycles: false
bibtex_author: Liu, Yunru and Gao, Tingran and Yang, Haizhao
author:
- given: Yunru
  family: Liu
- given: Tingran
  family: Gao
- given: Haizhao
  family: Yang
date: 2020-08-16
address: 
publisher: PMLR
container-title: Proceedings of The First Mathematical and Scientific Machine Learning
  Conference
volume: '107'
genre: inproceedings
issued:
  date-parts:
  - 2020
  - 8
  - 16
pdf: http://proceedings.mlr.press/v107/liu20a/liu20a.pdf
extras: []
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
