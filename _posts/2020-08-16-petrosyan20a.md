---
title: Neural network integral representations with the ReLU activation function
abstract: 'In this effort, we derive a formula for the integral representation of
  a shallow neural network with the ReLU activation function.  We assume that the
  outer weighs admit a finite $L_1$-norm with respect to Lebesgue measure on the sphere.  For
  univariate target functions we further provide a closed-form formula for all possible
  representations. Additionally, in this case our formula allows one to explicitly
  solve the least $L_1$-norm neural network representation for a given function.  '
layout: inproceedings
series: Proceedings of Machine Learning Research
id: petrosyan20a
month: 0
tex_title: "{Neural network integral representations with the ReLU activation function}"
firstpage: 128
lastpage: 143
page: 128-143
order: 128
cycles: false
bibtex_author: Petrosyan, Armenak and Dereventsov, Anton and Webster, Clayton G.
author:
- given: Armenak
  family: Petrosyan
- given: Anton
  family: Dereventsov
- given: Clayton G.
  family: Webster
date: 2020-08-16
address: 
publisher: PMLR
container-title: Proceedings of The First Mathematical and Scientific Machine Learning
  Conference
volume: '107'
genre: inproceedings
issued:
  date-parts:
  - 2020
  - 8
  - 16
pdf: http://proceedings.mlr.press/v107/petrosyan20a/petrosyan20a.pdf
extras: []
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
